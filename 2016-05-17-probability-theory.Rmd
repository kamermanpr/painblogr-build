---
post_title: 'The gganimate package in action: Probability theory'
post_author: 'Peter Kamerman'
post_date: '17 May 2016'
post_image: './images/posts/2016-05-17-probability-theory/post-image.png'
permalink:  '2016-05-17-probability-theory.html'
description: 'Using the gganimate package to illustrate the central limit theorem, and law of large numbers.'
output:
    html_document:
        template: './_templates/posts.html'
---

<br>

## Background
_(You can grab the full R script from  [GitHub](https://github.com/kamermanpr/miscellaneous/tree/master/central-limit-n-large-numbers), or view the RMarkdown output - with code - at [RStudio Connect](//beta.rstudioconnect.com/kamermanpr/central-limit-n-large-numbers/))._  

I have wanted to try David Robinson's (@drob) [gganimate](//github.com/dgrtwo/gganimate) package since I came across it a few months ago. The package extends Hadley Wickham's (@hadleywickham) [ggplot2](//github.com/hadley/ggplot2) package by adding a _'frame'_ aesthetic that provides a time factor to geoms, allowing them to be animated.

Recently, the opportunity to put the package through its paces arose while I was preparing materials for an [introductory biostatistics](//painblogr.org/biostatistics/) tutorial for undergrad students. I wanted to demonstrate the _central limit theorem_ and _law of large numbers_, and thought that animations would help deliver the message.

The central limit theorem provides a shortcut to knowing the sampling distribution, which is the probability distribution of a statistic (e.g., mean, proportion) for all possible samples from a population. The theorem is one of the cornerstones of probability theory because it allows you to make statements about the sampling distribution for a particular statistic without having to sample the entire population. As such, it forms the basis of statistical inference.

The central limit theorem states that the sampling distribution of an independent, random variable is normal or near-normal if a sufficiently large number of (equal-sized) samples are taken. If the sampling distribution for a statistic follows a normal or near-normal distribution we can make probability statements about the range of values in which the statistic lies. For example, there is a 68% probability that the sample statistic is within 1 standard deviation of the population value, and a 95% probability that it lies within about 2 standard deviations (see figure below). In the case of the sampling distribution, the standard deviation of the distribution is also called the _standard error_.

<!-- Use html to allow control over plot dimensions (480 x 480px) -->
<img src="./images/posts/2016-05-17-probability-theory/normal-distr.png"
style="height:343px;width:480px; display:block;margin-right:auto;margin-left:auto">

The size of the standard error also allows us to gauge the precision of the sample statistic, and this _'width'_ of the sampling distribution is dependent on the size of the samples. From a technical point of view, the standard error of the sample statistic is equal to the standard deviation of the population divided by the square root of the sample size ($se = \frac{\sigma}{\sqrt{n}}$). Basically, as the size of each sample increases the samples are more likely to be representative of the population, and therefore variability around the point estimate should decrease. The figure below shows the effect of increasing sample size on the precision of the standard error.

<img src="./images/posts/2016-05-17-probability-theory/sem-plot.png" style="height:480px;width:480px;display:block;margin-right:auto;margin-left:auto">

This leads us to the _law of large numbers_. At a simplistic level, the central limit theorem tells us about the shape of the sampling distribution, while the law of large numbers tells us where the centre of the distribution lies. From the law of large numbers we can show that the cumulative result from a large number of trials/samples tends towards the true value in the population. That is, the probability of an unusual outcome becomes smaller as the number of trials/samples increases. This convergence in probability is also called the _weak law of large numbers_.

## gganimate: the theories in action
I used the _gg\_animate_ function from the _gganimate_ package to put the two theories into action.

### Our population
The central limit theorem holds across different distributions, and to  illustrate this point I started with a population generated by taking a random sample (_N_ = 200,000) from the exponential distribution (right-skewed) with rate 1.

The density distribution of this dataset is shown in the figure below (the mean is marked by the orange line), and it served as the population from which samples were taken to demonstrate the central limit theorem and the law of large numbers.

``` r

###############
# Load packages
###############
library(gganimate) # Get it: devtools::install_github("dgrtwo/gganimate")
library(ggplot2)
library(dplyr)
library(tidyr)

#########################
# Right-skewed population
#########################

# Create a right-skewed dataset
foo <- rexp(200000)

# Convert 'foo' into a data.frame for plotting
distr <- data_frame(data = foo)

# Plot the original right-skewed distribution
distr.plot <- ggplot(distr, aes(data)) +
    geom_density(fill = '#0072B2', colour = '#0072B2') +
    geom_vline(xintercept = mean(foo), colour = "#E69F00", size = 1) +
    scale_x_continuous(limits = c(0, 14),
                       breaks = c(0, 2, 4, 6, 8, 10, 12, 14)) +
    scale_y_continuous(limits = c(0, 1),
                       breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1)) +
    labs(x = '\nValue', y = 'Probability\n') +
    theme(plot.title = element_text(size = 17),
          axis.text = element_text(size = 17),
          axis.title = element_text(size = 17),
          axis.ticks = element_blank(),
          panel.grid.major = element_line(colour = 'gray80', size = 0.3),
          panel.background = element_blank())

# Save the plot
ggsave('original-distr.png', distr.plot)

```

<!-- Use html to allow control over plot dimensions (480 x 480px) -->
<img src="./images/posts/2016-05-17-probability-theory/original-distr.png" style="height:480px;width:480px;display:block;margin-right:auto;margin-left:auto;">

### The central limit theorem in action
To demonstrate the central limit theorem, I took 5000 samples (without replacement) of _n_ = 200 each from the 'population' of 200,000, and calculated the mean for each sample. I then tabulated the frequency at which sample means occurred across the 5000 samples, and used these data to plot a frequency histogram. However, in addition to the usual ggplot2 code, I added the gganimate aesthetic functions (**'frame'** and **'cumulative'**) to the geom\_bar aesthetics. Adding these new aesthetics allowed the gg_animate function to take the ggplot2 object and to sequentially add the frequency bins of sample means as frames in an animation ('frame'), and for each frame to built cumulatively on the previous one ('cumulative = TRUE').  

``` r

#######################
# Central limit theorem
#######################

# Create an empty list, and a 'for loop' counter
bar <- list()
cnt <- 1:5000

# Take 5000 samples of n = 200 from 'foo' and make a list of sample means.
for(i in cnt){
    bar[[i]] <- mean(sample(foo, size = 200))

# Process data in 'bar' for plotting
## Unlist and round to reduce the number of bins for CLT plot
baz <- round(unlist(bar), 2)

## cross-tabulate the data to get frequency bins
boo <- xtabs(~baz)

## Extract the names ('bins')
nam <- names(boo)

## Make data.frame for plotting
bee <- data_frame(sample = c(1:length(boo)),
                  mean = as.numeric(nam),
                  freq = as.numeric(boo))

# Plot the data
clt <- ggplot(bee, aes(y = freq, x = mean, frame = sample)) +
    geom_bar(aes(cumulative = TRUE), stat = 'identity',
             fill = '#0072B2', colour = '#0072B2') +
    geom_vline(xintercept = mean(foo), colour = "#E69F00", size = 1) +
    scale_x_continuous(limits = c(0.7, 1.3),
                       breaks = seq(from = 0.7, to = 1.3, by = 0.1)) +
    labs(title = 'bin counter =',
         x = '\nSample mean', y = 'Frequency\n') +
    theme(plot.title = element_text(size = 20),
          axis.text = element_text(size = 20),
          axis.title = element_text(size = 20),
          axis.ticks = element_blank(),
          panel.grid.major = element_line(colour = 'gray80', size = 0.3),
          panel.background = element_blank())

# Animate plots with gg_animate
gg_animate(clt, interval = 0.2, 'central-limit.gif')

```

The output is shown in the next figure, and as you can see, despite the samples being obtained from a right-skewed distribution, the distribution of sample means is roughly normal, and centred around the mean of the population (orange line).

<img src="./images/posts/2016-05-17-probability-theory/central-limit.gif"
style="display:block;margin-right:auto;margin-left:auto;max-width:100%;">

### The law of large numbers in action
To illustrate the law of large numbers, I took the 5000 sample means I had generated and calculated a cumulative mean across the samples. The cumulative mean was then plotted against the sample number in ggplot2, with the gganimate **'frame'** and **'cumulative'** aesthetics added to geom\_line, which allowed gg_animate to depict the changing cumulative mean across increasing sample number as frames in the animation.

``` r

######################
# Law of large numbers
######################

# Process the data in 'bar' for plotting
## Unlist
baz_2 <- unlist(bar)

## Calculate the cumulative mean for plotting
zoot <- baz_2 %>%
    data_frame(mean = .) %>%
    mutate(cmean = round(cummean(mean),4),
           count = 1:length(mean)) %>%
    select(count, mean, cmean)

# Plot the data
lln <- ggplot(zoot_short, aes(y = cmean, x = count)) +
    geom_line(aes(frame = count, cumulative = TRUE),
              colour = '#0072B2') +
    geom_hline(yintercept = mean(foo), colour = "#E69F00", size = 1) +
    labs(title = 'Sample counter =',
         x = '\nSample number', y = 'Cumulative mean\n') +
    theme(plot.title = element_text(size = 20),
          axis.text = element_text(size = 20),
          axis.title = element_text(size = 20),
          axis.ticks = element_blank(),
          panel.grid.major = element_line(colour = 'gray80', size = 0.3),
          panel.background = element_blank())

# Animate plots with gg_animate
gg_animate(lln, interval = 0.2, 'law-large-numbers.gif')

```

The resulting figure is shown below, and shows the cumulative mean of sample means getting closer to the population mean as the number of samples increases.

<img src="./images/posts/2016-05-17-probability-theory/law-large-numbers.gif"
style="display:block;margin-right:auto;margin-left:auto;max-width:100%;">

So there you have it, the central limit theorem and the law of large numbers graphically illustrated using the awesome gganimate package in combination with ggplot2. Making the creation of animated ggplots simple.

****

## tl;dr

#### GitHub
You can clone the full _RMarkdown_ file from  [GitHub](//github.com/kamermanpr/miscellaneous/tree/master/central-limit-n-large-numbers), or view the file at [RStudio Connect](//beta.rstudioconnect.com/kamermanpr/central-limit-n-large-numbers/).

#### ggplot2 extensions
You can find more extensions for ggplot from [ggplot2 extensions](//www.ggplot2-exts.org/index.html).

#### Oops
The little I know about stats is dangerous, so if you spot an error please let me know by submitting an [issue](//github.com/kamermanpr/miscellaneous/issues) on GitHub or by adding a comment below.
